## C1. Configuring vpp vswitch in worker node

```bash
sudo vppctl set interface state FortyGigabitEthernetaf/0/0 up
sudo vppctl set interface state FortyGigabitEthernetaf/0/1 up

sudo vppctl set interface l3 memif1/0
sudo vppctl set interface l3 memif2/0
sudo vppctl show mode
```

> Output example:
>
> vpp# show int
>         Name               Idx    State  MTU (L3/IP4/IP6/MPLS)     Counter          Count
> FortyGigabitEthernetaf/0/0        1      **up**          9000/0/0/0
> FortyGigabitEthernetaf/0/1        2      **up**          9000/0/0/0
> local0                            0     down          0/0/0/0
> memif1/0                          3      up          9000/0/0/0
> memif2/0                          4      up          9000/0/0/0
>
> vpp# clear interfaces
>
> vpp# show pci
> Address      Sock VID:PID     Link Speed   Driver          Product Name                    Vital Product Data
> 0000:3d:00.0   0  8086:37d2   2.5 GT/s x1  i40e            Example VPD                     RV: 0x d7
> 0000:3d:00.1   0  8086:37d2   2.5 GT/s x1  i40e            Example VPD                     RV: 0x d7
> 0000:af:00.0   1  8086:1583   8.0 GT/s x8  vfio-pci        XL710 40GbE Controller          RV: 0x 86
> 0000:af:00.1   1  8086:1583   8.0 GT/s x8  vfio-pci        XL710 40GbE Controller          RV: 0x 86
>
> vpp# show memif

- Configuring parallel containers:
```bash
sudo vppctl test l2patch rx FortyGigabitEthernetaf/0/0 tx memif1/0
sudo vppctl test l2patch rx FortyGigabitEthernetaf/0/1 tx memif2/0
sudo vppctl test l2patch rx memif1/0 tx FortyGigabitEthernetaf/0/0 
sudo vppctl test l2patch rx memif2/0 tx FortyGigabitEthernetaf/0/1

sudo vppctl show l2patch
```

- Del connection between interface
```bash
[root@worker ~]# sudo vppctl test l2patch rx FortyGigabitEthernetaf/0/1 tx memif2/0 del
```

- Configuring chained containers:

```bash
sudo vppctl test l2patch rx FortyGigabitEthernetaf/0/0 tx memif1/0
sudo vppctl test l2patch rx FortyGigabitEthernetaf/0/1 tx memif4/0
sudo vppctl test l2patch rx memif2/0 tx memif3/0
sudo vppctl test l2patch rx memif3/0 tx memif2/0
sudo vppctl test l2patch rx memif4/0 tx FortyGigabitEthernetaf/0/1
sudo vppctl test l2patch rx memif1/0 tx FortyGigabitEthernetaf/0/0
```

- Show route table:
```
[root@worker ~]# sudo vppctl show l2patch
FortyGigabitEthernetaf/0/0 -> memif3/0
FortyGigabitEthernetaf/0/1 -> memif4/0
                   DELETED -> DELETED
                   DELETED -> DELETED
                  memif3/0 -> FortyGigabitEthernetaf/0/0
                  memif4/0 -> FortyGigabitEthernetaf/0/1

```
- Checking DPDK interface:

  ```bash
  [root@worker usertools]# ./dpdk-20.11/usertools/dpdk-devbind.py --status
  
  Network devices using DPDK-compatible driver
  ============================================
  
  0000:af:00.0 'Ethernet Controller XL710 for 40GbE QSFP+ 1583' drv=vfio-pci unused=i40e
  0000:af:00.1 'Ethernet Controller XL710 for 40GbE QSFP+ 1583' drv=vfio-pci unused=i40e
  
  Network devices using kernel driver
  ===================================
  
  0000:3d:00.0 'Ethernet Connection X722 for 10GBASE-T 37d2' if=eno1 drv=i40e unused=vfio-pci *Active*
  0000:3d:00.1 'Ethernet Connection X722 for 10GBASE-T 37d2' if=eno2 drv=i40e unused=vfio-pc
  ```

## C2.Run L2fwd, L3fwd, testpmd on POD
- On master node:

`kubectl exec -it userspace-vpp-pod-1 -- /bin/bash`

Each application runs on a different socket. Show socket file: `ls -la /run/vpp/cni/usrspcni`

```bash
l2fwd -n 4 -l 7-10 --master-lcore 7 --vdev=net_memif1,socket=/run/vpp/cni/usrspcni/memif-6afac1a69b32-net1.sock,role=slave --vdev=net_memif2,socket=/run/vpp/cni/usrspcni/memif-6afac1a69b32-net2.sock,role=slave --no-pci -- -p 0x3 -T 10 --no-mac-updating

testpmd --huge-dir=/dev/hugepages --file-prefix=huge -l 1,2 --vdev=net_memif1,socket=/run/vpp/cni/usrspcni/memif-6afac1a69b32-net1.sock --vdev=net_memif2,socket=/run/vpp/cni/usrspcni/memif-6afac1a69b32-net2.sock -n 2 -- -i --txd=1024 --rxd=1024
```
```bash
Output example:
[root@vpp-pod /]# ls
bin  dev  docker-entrypoint.sh  etc  home  lib  lib64  lost+found  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var
[root@vpp-pod /]# ls -la /run/vpp/cni/usrspcni/
total 0
drwx------. 2 root root 80 Mar 11 11:21 .
drwxr-xr-x. 3 root root 22 Mar 11 11:21 ..
srwxrwxr-x. 1 root  993  0 Mar 11 11:21 memif-6afac1a69b32-net1.sock
srwxrwxr-x. 1 root  993  0 Mar 11 11:21 memif-6afac1a69b32-net2.sock
[root@vpp-pod /]# l2fwd -n 4 -l 7-10 --master-lcore 7 --vdev=net_memif1,socket=/run/vpp/cni/usrspcni/memif-6afac1a69b32-net1.sock,role=slave --vdev=net_memif2,socket=/run/vpp/cni/usrspcni/memif-6afac1a69b32-net2.sock,role=slave --no-pci -- -p 0x3 -T 10 --no-mac-updating
ENTER dpdk-app:
 argc=16
 l2fwd -n 4 -l 7-10 --master-lcore 7 --vdev=net_memif1,socket=/run/vpp/cni/usrspcni/memif-6afac1a69b32-net1.sock,role=slave --vdev=net_memif2,socket=/run/vpp/cni/usrspcni/memif-6afac1a69b32-net2.sock,role=slave --no-pci -- -p 0x3 -T 10 --no-mac-updating
EAL: Detected 80 lcore(s)
EAL: Detected 2 NUMA nodes
EAL: Multi-process socket /var/run/dpdk/rte/mp_socket
EAL: Selected IOVA mode 'VA'
EAL: No available hugepages reported in hugepages-1048576kB
EAL: Probing VFIO support...
EAL: VFIO support initialized
EAL: No legacy callbacks, legacy socket not created
MAC updating disabled
Lcore 7: RX port 0
Lcore 8: RX port 1
Initializing port 0... done:
Port 0, MAC address: E2:C9:D9:E1:FB:34

Initializing port 1... done:
Port 1, MAC address: 52:6C:6F:AF:A3:D2


Checking link status.done
Port0 Link Up. Speed 10000 Mbps - full-duplex
Port1 Link Up. Speed 10000 Mbps - full-duplex
L2FWD: entering main loop on lcore 8
L2FWD:  -- lcoreid=8 portid=1
L2FWD: entering main loop on lcore 7
L2FWD:  -- lcoreid=7 portid=0

Port statistics ====================================
Statistics for port 0 ------------------------------
Packets sent:                        0
Packets received:                    0
Packets dropped:                     0
Statistics for port 1 ------------------------------
Packets sent:                        0
Packets received:                    0
Packets dropped:                     0
Aggregate statistics ===============================
Total packets sent:                  0
Total packets received:              0
Total packets dropped:               0
====================================================
L2FWD: lcore 10 has nothing to do
L2FWD: lcore 9 has nothing to do
```



## C3. Configuring traffic generator (TREX)

- Configure DPDK running vfio-pci driver
``` bash
sudo yum install -y kernel-devel-`uname -r`
sudo yum install -y kernel
sudo yum install -y kernel-devel 
sudo yum group install -y "Development tools"
sudo reboot

tar -zxvf i40e-2.14.13.tar.gz
cd i40e-2.14.13.tar.gz/src
make
make install
modprobe i40e
lsmod | grep i40e
modinfo i40e | grep ver
modprobe vfio-pci

./dpdk-20.11/usertools/dpdk-devbind.py -s
./dpdk-20.11/usertools/dpdk-devbind.py -b vfio-pci 0000:86:00.0 0000:86:00.1
```

> ```
> Output example
> [root@tgen ~]# ./dpdk-20.11/usertools/dpdk-devbind.py -s
> 
> Network devices using DPDK-compatible driver
> ============================================
> 
> 0000:86:00.0 'Ethernet Controller XL710 for 40GbE QSFP+ 1583' drv=vfio-pci unused=i40e
> 0000:86:00.1 'Ethernet Controller XL710 for 40GbE QSFP+ 1583' drv=vfio-pci unused=i40e
> 
> Network devices using kernel driver
> ===================================
> 
> 0000:3d:00.0 'Ethernet Connection X722 for 10GBASE-T 37d2' if=eno1 drv=i40e unused=vfio-pci *Active*
> 0000:3d:00.1 'Ethernet Connection X722 for 10GBASE-T 37d2' if=eno2 drv=i40e unused=vfio-pci
> ```

- Configure hugepages

  ```bash
  cat /etc/default/grub
  GRUB_TIMEOUT=5
  GRUB_DISTRIBUTOR="$(sed 's, release .*$,,g' /etc/system-release)"
  GRUB_DEFAULT=saved
  GRUB_DISABLE_SUBMENU=true
  GRUB_TERMINAL_OUTPUT="console"
  GRUB_CMDLINE_LINUX="crashkernel=auto spectre_v2=retpoline rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet intel_iommu=on default_hugepagesz=1G hugepagesz=1G hugepages=8 hugepagesz=2M hugepages=4096"
  GRUB_DISABLE_RECOVERY="true"
  ```

```bash
grub2-mkconfig -o /boot/grub2/grub.cfg
grub2-mkconfig -o /boot/efi/EFI/centos/grub.cfg
reboot
```

- Configure TREX:

```
wget https://trex-tgn.cisco.com/trex/release/v2.37.tar.gz
vi /etc/trex_cfg.yaml
```

```bash
Output example:
[root@tgen ~]# cat /etc/trex_cfg.yaml
- version         : 2
  interfaces      : ["86:00.0","86:00.1"]
  port_limit      : 2
  enable_zmq_pub  : true  # enable publisher for stats data
  c               : 4

# for system of 1Gb/sec NIC or VM enable this

  port_bandwidth_gb : 40  # port bandwidth 10Gb/sec , for VM put here 1 for XL710 put 40
  platform :
        master_thread_id  : 0
        latency_thread_id : 5
        dual_if   :
             - socket   : 0
               threads  : [1,2,3,4,6,7]
  port_info       :  # set eh mac addr
          - dest_mac        :  40:a6:b7:19:f2:39        # port 0 src, dest mac of NIC card on TREX
            src_mac         :  40:a6:b7:19:f2:38
          - dest_mac        :  40:a6:b7:19:f2:38        # port 1
            src_mac         :  40:a6:b7:19:f2:39
```

```bash
./t-rex-64 -i -c 10

*** In another shell:
./opt/trex/v2.82/trex-console
tui
start -f stl/bench.py -t size=1518 -p 0 -m 100% --force -d 20
start -f stl/bench.py -t size=64 -p 0 -m 100% --force -d 20

Cause corruption testpmd && trex	
	start -f stl/imix.py -p 0 -m 100% --force
```

Refer: 
	https://trex-tgn.cisco.com/trex/doc/trex_stateless_bench.html

